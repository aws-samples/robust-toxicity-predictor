## Building a Robust Text-based toxicity Predictor

This repository contains code to showcase how to train a transformer-based toxicity language classifier using Huggingface, test the trained model on adversarial examples, and then perform adversarial training and analyze its effect on the trained toxicity classifier.

## Repo Structure
```bash
+-- notebooks
|   +-- BuildingARobustTextBasedToxicityPredictor.ipynb
+-- data
|   +-- sample_submission.csv.zip
|   +-- test.csv.zip
|   +-- test_labels.csv.zip
|   +-- train.csv.zip
+-- CODE_OF_CONDUCT.md
+-- CONTRIBUTING.md
+-- LICENSE.txt
+-- README.md
```

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This library is licensed under the MIT-0 License. See the LICENSE file.

